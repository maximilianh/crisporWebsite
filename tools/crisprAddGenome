#!/usr/bin/env python2

import logging, sys, optparse, os, shutil, glob, json, subprocess, gzip, re, StringIO

try:
    from urllib import urlopen
except:
    from urllib.request import urlopen

from collections import namedtuple
from os.path import *

import MySQLdb # install with "sudo apt-get install python-mysqldb"

# Todo to make this CGIable:
# - run mac2unix and dos2unix onto the input file, remove newlines, refuse files that still contain a newline
# - refuse files with ":" in any sequence identifier
# todo: add genbank downloader, e.g. 
# wget -O NC_001416.1.fasta 'https://www.ncbi.nlm.nih.gov/search/api/sequence/NC_001416.1/?report=fasta'

# temp dir on local disk
tmpDir = os.environ.get("TMPDIR", "/tmp")
if isdir("/tmp2"):
    tmpDir = "/tmp2"

global debugMode
global crisprGenomeDir

# directory where the genomes are stored for the crispr tool
crisprGenomeDir = "/var/www/crispor/genomes/"
#crisprGenomeDir = "/tmp"

debugMode = False

# just plough ahead, do not check for existing files
global FORCE
FORCE = False

ENSGRELEASE = "42"

smallCutoff = 500000

# === COMMAND LINE INTERFACE, OPTIONS AND HELP ===
parser = optparse.OptionParser("""usage: %prog [options] ens|ucsc|fasta|ncbi <taxId1> <taxId2> ... - add genome to crispr site

queries UCSC or ensembl database for all assemblies of genome, 
takes the newest one, downloads it, indexes it with bwa,
tries to find some gene model set and moves everything into the crispr directories 

if mode is "fasta":
- instead of taxon ID, the fasta file has to be provided as the first argument
- fasta file can be local or a http or ftp URL, can be gzipped
- ! fasta file seq IDs must not include | or other strange characters (fix this in code?)
- downloads or copies fasta file, indexes it
- takes genome info from the --desc option

if mode is "ucsc":
- accepts UCSC db identifiers instead of taxonId

if mode is "ncbi":
- accepts a space-separated list of Refseq or Genbank assembly identifiers, e.g. GCF_000203835.1

if mode is "genbank"
- accepts a space-spearate list of Genbank identifiers, e.g. JF797219.1

Example:
sudo crisprAddGenome fasta /tmp2/LAEVIS_7.1.repeatMasked.fa --desc 'xenBaseLaevis71|Xenopus laevis|X. laevis|Xenbase V7.1'
""")

parser.add_option("-d", "--debug", dest="debug", action="store_true", help="show debug messages")
parser.add_option("-a", "--auto", dest="auto", action="store_true", help="auto-mode: don't ask the user, always choose the newest assembly")
parser.add_option("-g", "--genes", dest="onlyGenes", action="store_true", help="download only gene models, not the assembly and replace the existing gene models. Also write assembly info file genomeInfo.tab")
parser.add_option("", "--geneTable", dest="geneTable", action="store", help="in UCSC mode: use another gene table than ensGene, e.g. refGene or wgEncodeGencodeBasicV22 or 'none' to deactivate gene table download", default="ensGene")
parser.add_option("", "--symFixFile", dest="symFixFile", action="store", help="in UCSC mode: add a file with some manual geneId<tab>symbol mappings to fix the provided ones")
parser.add_option("", "--desc", dest="desc", action="store", help="in manual mode: description of genome, a | separated string of dbName, scientificName, commonName, dbVersion. Make sure to quote this string. Example: 'hg19|Homo sapiens|Human|Feb 2009 (GRCh37)'")
parser.add_option("", "--gff", dest="gffFname", action="store", help="read gene models from this gff3 file")
parser.add_option("-u", "--altGff", dest="altGff", action="store_true", help="use UCSC gff3 converter instead of tophat's")
parser.add_option("", "--baseDir", dest="baseDir", action="store", help="baseDir for genomes, default is %default", default=crisprGenomeDir)
parser.add_option("-f", "--force", dest="force", action="store_true", help="do not check for existing files")
#parser.add_option("-f", "--file", dest="file", action="store", help="run on file") 
#parser.add_option("", "--test", dest="test", action="store_true", help="do something") 
(options, args) = parser.parse_args()

if options.debug:
    logging.basicConfig(level=logging.DEBUG)
else:
    logging.basicConfig(level=logging.INFO)
# ==== FUNCTIONs =====
def errAbort(msg):
    " show msg and abort. Like errAbort.c "
    print(msg)
    print("Need help or have feedback? Email crispor@tefor.net")
    exit(0)

def runCmd(cmd, mustRun=True, useSys=False):
    " wrapper around os.system that prints error messages "
    if debugMode:
        print(cmd)
    if useSys:
        ret = os.system(cmd)
    else:
        args = ["/bin/bash", "-e", "-o", "pipefail", "-c", cmd]
        logging.info("Running: %s" % args)
        args.append(cmd)
        ret = subprocess.call(args)
    if ret!=0 and mustRun:
        print(("Could not run command %s" % cmd))
        if mustRun:
            #sys.exit(0)
            assert(False)
        else:
            return -1

    return ret
    
def lineFileNext(fh, skipLines=0):
    """
        parses tab-sep file with headers as field names
        yields collection.namedtuples
        strips "#"-prefix from header line
    """
    for i in range(skipLines):
        fh.readline()
    line1 = fh.readline()
    line1 = line1.strip("\n").strip("#")
    headers = line1.split("\t")
    headers = [h.strip() for h in headers]
    Record = namedtuple('tsvRec', headers)
   
    for line in fh:
        line = line.rstrip("\n")
        fields = line.split("\t")
        try:
            rec = Record(*fields)
        except Exception as msg:
            logging.error("Exception occured while parsing line, %s" % msg)
            logging.error("Filename %s" % fh.name)
            logging.error("Line was: %s" % repr(line))
            logging.error("Does number of fields match headers?")
            logging.error("Headers are: %s" % headers)
            #raise Exception("wrong field count in line %s" % line)
            continue
        # convert fields to correct data type
        yield rec

def sqlConnect(db):
    """ connect to ucsc sql server"""
    host, user, passwd = "genome-mysql.cse.ucsc.edu", "genomep", "password"
    conn = MySQLdb.connect(host=host, user=user, passwd=passwd, db=db)
    return conn

def querySql(conn, query):
    " return all rows for query as namedtuples "
    cursor = conn.cursor()
    rows = cursor.execute(query)
    data = cursor.fetchall()
    colNames = [desc[0] for desc in cursor.description]
    Rec = namedtuple("MysqlRow", colNames)
    recs = [Rec(*row) for row in data]
    cursor.close()
    return recs

def parseConf(fname):
    " parse a hg.conf style file, return as dict key -> value (all strings) "
    conf = {}
    for line in open(fname):
        line = line.strip()
        if line.startswith("#"):
            continue
        elif line.startswith("include "):
            inclFname = line.split()[1]
            absFname = normpath(join(dirname(fname), inclFname))
            if os.path.isfile(absFname):
                inclDict = parseConf(absFname)
                conf.update(inclDict)
        elif "=" in line: # string search for "="
            key, value = line.split("=")
            conf[key] = value
    return conf

hgConf = None

def parseHgConf():
    """ return hg.conf as dict key:value. """
    global hgConf
    if hgConf is not None:
        return hgConf

    hgConf = dict() # python dict = hash table

    #confDir = os.path.dirname(__file__) # look for hg.conf in parent dir
    fname = expanduser("~/.hg.conf")
    hgConf = parseConf(fname)

    return hgConf

def cfgOption(name, default=None):
    " return hg.conf option or default "
    return hgConf.get(name, default)

def hConnectCentral():
    " similar to src/hg/lib/hdb.c:hConnectCentral. We use a much simpler cache, because we usually read all rows into memory. "

    parseHgConf()
    centralDb = cfgOption("central.db")
    if centralDb is None:
        errAbort("Could not find central.db in hg.conf. Installation error.")

    centralUser = cfgOption("central.user")
    if centralUser is None:
        errAbort("Could not find central.user in hg.conf. Installation error.")

    centralPwd = cfgOption("central.password")
    if centralPwd is None:
        errAbort("Could not find central.password in hg.conf. Installation error.")

    centralHost = cfgOption("central.host")
    if centralHost is None:
        errAbort("Could not find central.host in hg.conf. Installation error.")

    conn = sqlConnect(centralDb)

    centralConn = conn
    return conn

def selectUcscGenomesByDb(db):
    " like selectUcscGenomes but only for a single genome and by the ucsc db id, not taxonId "
    conn = hConnectCentral()
    query = 'SELECT * FROM dbDb WHERE name="%s" ORDER BY orderKey DESC' % db
    rows = querySql(conn, query)
    assert(len(rows)==1)
    return rows

def selectUcscGenomes(taxIds, quiet):
    " given a list of taxIds, let the user select an assembly and return a list of dbDb rows for them "
    conn = sqlConnect("hgcentral")
    data = {}
    dbRows = []
    for taxId in taxIds:
        print("taxon ID or db name:",taxId)
        print()
        if taxId.isdigit():
            query = 'SELECT * FROM dbDb WHERE taxId="%s" ORDER BY orderKey DESC' % taxId
        else:
            query = 'SELECT * FROM dbDb WHERE name="%s" ORDER BY orderKey DESC' % taxId
        rows = querySql(conn, query)

        if len(rows)==0:
            print("Sorry, this taxon ID is not served by UCSC")
            continue

        choice = None
        possChoices = list(range(1, len(rows)+1))
        if quiet or len(possChoices)==1:
            choice = possChoices[-1]
        while choice not in possChoices:
            print("Please select the assembly:")
            print()
            for i, row in enumerate(rows):
                print(i+1, "- ", row.name, " - ", row.description)
            print()
            print("Type the number of the assembly and press Return:")
            print("(If you just enter Return, number %d will be used)" % possChoices[-1])
            num = input()
            if num=="":
                num = str(possChoices[-1])
            if not num.isdigit():
                print("error: you did not type a number")
                continue

            num = int(num)
            if num in possChoices:
                choice = num
            else:
                print("error: not a valid number you can select, select one of", possChoices)
        dbRows.append(rows[choice-1])

    return dbRows

def printMsg(msg):
    " print with some highlighting "
    print(" ==== "+msg+" ==== ")

def moveToDest(outFnames, finalDbDir):
    """ copy filenames in outFnames list to finalDbDir, remove any .gz strings. skip existing files.
    relative directories are stripped.
    """
    if not isdir(finalDbDir):
        os.makedirs(finalDbDir)
    for outFname in outFnames:
        finalPath = join(finalDbDir, basename(outFname))
        finalPath = finalPath.replace(".gz", "")
        if isfile(finalPath):
            if not isfile(outFname):
                print("does not exist, not copying %s" % outFname)
            else:
                print("already exists: copying %s to %s " % (outFname, finalPath))
                shutil.copyfile(outFname, finalPath)
        else:
            print("moving %s to crispr genome dir %s" % (outFname, finalDbDir))
            shutil.move(outFname, finalPath)

def writeGenomeInfo(row, addUcsc=False):
    " write basic genome assembly info to finalDbDir "
    db = row.name
    genomeInfoPath = join(crisprGenomeDir, db, "genomeInfo.tab")
    giFh = open(genomeInfoPath, "w")

    headers = list(row._fields)
    if addUcsc:
        headers.append("server")
    giFh.write("#"+"\t".join(headers))
    giFh.write("\n")

    row = [str(x) for x in row]
    giFh.write("\t".join(row))
    if addUcsc:
        giFh.write("\t"+"ucsc")
    giFh.write("\n")

    giFh.close()
    print(("wrote %s" % genomeInfoPath))

def indexFasta(faTmp, db, twoBitTmp, sizesTmp, outFnames):
    " index fasta with bwa and make chrom sizes. Adds file names creates to outFnames "
    if isfile(sizesTmp) and not FORCE:
        printMsg("%s exists - not indexing with BWA and not converting to twobit" % sizesTmp)
        return

    if not isfile(twoBitTmp):
        printMsg("Converting fasta to 2bit")
        cmd = "faToTwoBit %s %s" % (faTmp, twoBitTmp)
        runCmd(cmd)

    sizesTmp2 = sizesTmp+".tmp"

    printMsg("Making chrom sizes")
    cmd = "twoBitInfo %s %s" % (twoBitTmp, sizesTmp2)
    runCmd(cmd)

    chromCount = len(open(sizesTmp2).read().splitlines())
    if chromCount > 500000:
        errAbort("ERROR: genome has %d chromosomes - too many. This will be very slow to process with crispor." % chromCount)

    printMsg("Indexing fasta with BWA")
    cmd = "bwa index %s" % faTmp
    runCmd(cmd)

    printMsg("Deleting fasta")
    cmd = "rm %s" % faTmp
    runCmd(cmd)

    os.rename(sizesTmp2, sizesTmp)

    dbTmpDir = dirname(faTmp)
    outFnames.extend(glob.glob(join(dbTmpDir, "*.fa.*"))) # bwa output files
    return sizesTmp

def fixSymFile(accToSymTmp, symFixFile):
    " take a key,val file, append the key,vals from symFixFile to it "
    data = {}
    for line in open(accToSymTmp):
        key, val = line.strip().split("\t")
        data[key] = val
    for line in open(symFixFile):
        key, val = line.strip().split("\t")
        data[key] = val

    ofh = open(accToSymTmp, "w")
    for key, val in data.items():
        ofh.write("%s\t%s\n" % (key, val))
    ofh.close()

def ucscCleanup(dbTmpDir, accToSymTmp, segTmp, sizesTmp, twoBitTmp, finalDbDir):
    " copy seg, sizes and twobit to finalDbDir and clean up dbTmpDir "
    if accToSymTmp:
        cmd = "rm %s" % accToSymTmp
        runCmd(cmd)

    printMsg("Moving output files into crispr tool directory")
    outFnames = glob.glob(join(dbTmpDir, "*.fa.*")) # bwa output files
    if segTmp:
        outFnames.extend([segTmp])

    outFnames.extend([sizesTmp, twoBitTmp])
    if not isdir(finalDbDir):
        os.makedirs(finalDbDir)
    moveToDest(outFnames, finalDbDir)

    cmd = "rm -rf %s" % dbTmpDir
    runCmd(cmd)

def geneToSegment(geneTmp, accToSymTmp, sizesTmp, segTmp):
    " convert genes to segments "
    printMsg("Downloading gene models to segments")
    # the awk command translates spaces to underscores. genePredToBed cannot deal with these.
    cmd = """cat %(geneTmp)s | cut -f2- | awk 'BEGIN {FS=OFS="\t";} // { gsub(" " , "_", $1); gsub(" ", "_", $12); print }' | genePredToBed stdin stdout | bedToExons stdin stdout | lstOp replace stdin %(accToSymTmp)s | sort -u | bedSort stdin stdout | bedOverlapMerge /dev/stdin /dev/stdout | bedBetween stdin /dev/stdout -a -s %(sizesTmp)s | bedSort stdin %(segTmp)s""" % locals()
    runCmd(cmd)
    assert(getsize(segTmp)!=0) # no segments - email Max!

def indexLocalGenome(dbInfo, geneTable):
    " get and index genome at UCSC using geneTable for the gene annotations "
    db = dbInfo.name
    dbTmpDir = join(tmpDir, db)
    finalDbDir = join(crisprGenomeDir, db)

    try:
        os.makedirs(dbTmpDir)
        print(("made %s" % dbTmpDir))
    except:
        print(("%s already exists, not creating" % dbTmpDir))

    if isdir(finalDbDir):
        print("the directory %s already exists" % finalDbDir)
        print("looks like this genome has already been indexed")
        return


    printMsg("Genome: " + db)
    sizesTmp = join(dbTmpDir, db+".sizes")
    faTmp = join(dbTmpDir, db+".fa")
    twoBitTmp = join(dbTmpDir, db+".2bit")
    if isfile(sizesTmp):
        printMsg("%s exists - not indexing with BWA and not converting to twobit" % sizesTmp)
    else:
        printMsg("Copying 2bit")
        cmd = "cp /gbdb/%s/%s.2bit %s" % (db, db, twoBitTmp)
        runCmd(cmd)

        printMsg("Converting to fasta")
        faTmp = join(dbTmpDir, db+".fa")
        cmd = "twoBitToFa %s %s" % (twoBitTmp, faTmp)
        runCmd(cmd)

        indexFasta(faTmp, db, twoBitTmp, sizesTmp, [])

    # make transcript -> symbol file
    accToSymTmp = join(dbTmpDir, db+".transToName.txt")
    if geneTable=="ensGene":
        transToGeneTable = "ensemblToGeneName"
        printMsg("Getting ENSEMBL transcripts to gene name table")
        cmd = "hgsql %s -NB -e 'SELECT * from %s' > %s" % (db, transToGeneTable, accToSymTmp)
    else:
        printMsg("mapping transcript IDs to gene symbols via name2 field in genePred, table %s" % geneTable)
        cmd = "hgsql %s -NB -e 'SELECT * from %s' | cut -f2,13 | sort -u > %s" % (db, geneTable, accToSymTmp)
    runCmd(cmd)
    assert(getsize(accToSymTmp)!=0) # no symbols - email Max!

    # get the gene pred table, do not strip bin column
    geneTmp = join(dbTmpDir, "%s.genes.txt" % db)
    cmd = "hgsql %(db)s -NB -e 'SELECT * from %(geneTable)s' >  %(geneTmp)s" % locals()
    runCmd(cmd)

    # now convert the genes to segments. Do not keep the genes, because they're already on the UCSC browser
    segTmp = join(dbTmpDir, "%s.segments.bed" % db)
    geneToSegment(geneTmp, accToSymTmp, sizesTmp, segTmp)

    ucscCleanup(dbTmpDir, accToSymTmp, segTmp, sizesTmp, twoBitTmp, finalDbDir)

    writeGenomeInfo(dbInfo, addUcsc=True)

def getUcscGenomes(rows, geneTable, symFixFile, onlyGenes):
    " download and index genomes, geneFnames can be a comma-sep string with genePredTable,geneSyms "
    checkDir = True

    for row in rows:
        db = row.name
        dbTmpDir = join(tmpDir, db)
        finalDbDir = join(crisprGenomeDir, db)
        if checkDir:
            if isdir(dbTmpDir):
                if not onlyGenes:
                    print(("there exists already a directory %s" % dbTmpDir))
                    print ("are you sure there is not already a process in a different terminal that indexes this genome?")
                    print(("if you are sure, remove the directory with 'rm -rf %s' and retry" % dbTmpDir))
                    #sys.exit(1)
            else:
                os.makedirs(dbTmpDir)

            if isdir(finalDbDir):
                print("the directory %s already exists" % finalDbDir)
                print("looks like this genome has already been indexed")
                continue

        sizesTmp = join(dbTmpDir, db+".sizes")
        twoBitTmp = join(dbTmpDir, db+".2bit")
        if not onlyGenes:
            printMsg("Genome: " + db)
            printMsg("Downloading")
            cmd = "wget http://hgdownload.cse.ucsc.edu/goldenpath/%s/bigZips/%s.2bit -O %s" % (db, db, twoBitTmp)
            runCmd(cmd)

            printMsg("Converting to fasta")
            faTmp = join(dbTmpDir, db+".fa")
            cmd = "twoBitToFa %s %s" % (twoBitTmp, faTmp)
            runCmd(cmd)

            indexFasta(faTmp, db, twoBitTmp, sizesTmp, [])

        if geneTable=="none":
            accToSymTmp = None
            segTmp = None
        else:
            accToSymTmp = join(dbTmpDir, db+".ensemblToGeneName.txt")
            if geneTable!="ensGene":
                printMsg("Downloading mapping of %s transcript IDs to gene symbols" % geneTable)
                cmd = "wget http://hgdownload.cse.ucsc.edu/goldenPath/%s/database/%s.txt.gz -O - | zcat | cut -f2,13 | sort -u > %s" % (db, geneTable, accToSymTmp)
            else:
                printMsg("Downloading ensembl transcripts to gene name table")
                cmd = "wget http://hgdownload.cse.ucsc.edu/goldenPath/%s/database/ensemblToGeneName.txt.gz -O - | zcat > %s" % (db, accToSymTmp)
            runCmd(cmd)
            assert(getsize(accToSymTmp)!=0) # no symbols - email Max!

            if symFixFile:
                fixSymFile(accToSymTmp, symFixFile)

            printMsg("Downloading gene models")
            geneTmp = join(dbTmpDir, "genes.txt")
            cmd = "wget http://hgdownload.cse.ucsc.edu/goldenPath/%(db)s/database/%(geneTable)s.txt.gz -O - | zcat > %(geneTmp)s" % locals()
            runCmd(cmd)

            segTmp = join(dbTmpDir, "%s.segments.bed" % db)
            geneToSegment(geneTmp, accToSymTmp, sizesTmp, segTmp)

        ucscCleanup(dbTmpDir, accToSymTmp, segTmp, sizesTmp, twoBitTmp, finalDbDir)
        writeGenomeInfo(row, addUcsc=True)

def selectEnsGenomes(genomeIds):
    """ given a list of genomeIds or assembly names, get dbDb-like rows from Ensembl for them.
    The assembly name is the last part of the ftp path, e.g for ftp://ftp.ensembl.org/pub/current_fasta/mus_musculus_c3hhej/dna/
    the assembly name is mus_musculus_c3hhej. """
    # download ensembl, ensMetazoan, ensPlants species info JSONs
    # #http://rest.ensembl.org/info/species?content-type=application/json
    # create dbDb-like rows from json


    headers = ["name", "description", "nibPath", "organism", "defaultPos", "active", "orderKey", "genome", "scientificName", "htmlPath", "hgNearOk", "hgPbOk", "sourceName", "taxId", "server"]
    Rec = namedtuple("dbDb", headers)

    url1 = "http://rest.ensembl.org/info/species?content-type=application/json"
    #url2 = "http://rest.ensemblgenomes.org/info/species?content-type=application/json"

    fnames = [("ensMain.json", url1)]
    rows = []
    for fname, url in fnames:
        path = join(crisprGenomeDir, fname)
        logging.info("Reading %s" % path)
        if not isfile(path):
            logging.info("Could not find %s, downloading %s" % (path, url))
            data = urlopen(url).read()
            open(path, "w").write(data)
            
        content = open(path).read()
        orgDicts = json.loads(content)

        newOrgs = []
        for od in orgDicts["species"]:
            taxId = str(od["taxon_id"])
            name = od["name"]
            print(taxId, name, genomeIds)
            if taxId not in genomeIds:
                if name not in genomeIds:
                    continue

            no = {}
            no["server"] = od["division"]
            scName = od["name"].replace("_", " ").capitalize()
            parts = scName.split()
            shortName = "".join(parts[0][:3]).title()+"".join(parts[1][:3]).title()+od["assembly"]

            no["name"] = "ens"+str(od["release"])+shortName
            if od["accession"]:
                no["description"] = "%s %s (%s, %s)" % (od["division"], od["release"], od["assembly"], od["accession"])
            else:
                no["description"] = "%s %s (%s)" % (od["division"], od["release"], od["assembly"])
            no["nibPath"] = od["release"]
            commName = od["common_name"]
            if commName==None:
                commName = scName
            no["organism"] = commName.capitalize()
            no["defaultPos"] = ""
            no["active"] = ""
            no["orderKey"] = "0"
            no["genome"] = commName.capitalize()
            no["scientificName"] = scName
            no["htmlPath"] = ""
            no["hgNearOk"] = ""
            no["hgPbOk"] = ""
            no["sourceName"] = od["assembly"]
            no["taxId"] = od["taxon_id"]
            row = [no[k] for k in headers]
            row = Rec(*row)
            rows.append(row)

    assert(len(rows)!=0) # no genome found?
    return rows

def getEnsDownloadUrls(division, org, assembly, release, dataType):
    " get the ftp url for a given ensembl species file, dataType is fasta or gtf"
    # ftp://ftp.ensemblgenomes.org/pub/current/plants/fasta/arabidopsis_thaliana/dna/Arabidopsis_thaliana.TAIR10.23.dna_sm.toplevel.fa.gz
    logging.info("Getting URL for: Ensembl group %s, org %s, assembly %s, release %s, dataType %s" % (division, org, assembly, release, dataType))
    org = org.replace(" ", "_").lower()
    orgCap = org.capitalize()
    division=division.lower()

    if division=="ensemblvertebrates":
        url = "ftp://ftp.ensembl.org/pub/current_%(dataType)s/%(org)s/" % locals()
    else:
        divDir = division.replace("ensembl","")
        url = "ftp://ftp.ensemblgenomes.org/pub/current/%(divDir)s/%(dataType)s/%(org)s/" % locals()
        release = ENSGRELEASE # XX hard-coded, bug in ensembl gives wrong rel codes right now

    if dataType=="fasta":
        url += "dna/"

    url += "%(orgCap)s.%(assembly)s" % locals()

    #if division!="ensembl" or dataType!="fasta":
        #url += ".%(release)s" % locals()

    if dataType=="fasta":
        url += ".dna_sm.toplevel.fa.gz"
    elif dataType=="gtf":
        url += ".%(release)s.gtf.gz" % locals()

    url = url.replace("_bd","") # July 2015, was necessary for a genome
    return url
        

def getEnsGenomes(genomeRows, onlyGenes):
    " download and index ensembl genomes from dbDb-like rows. "
    for row in genomeRows:
        db = row.name
        dbTmpDir = join(tmpDir, db)
        finalDbDir = join(crisprGenomeDir, db)

        if not onlyGenes:
            if isdir(dbTmpDir):
                print(("there exists already a directory %s" % dbTmpDir))
                print ("are you sure there is not already a process in a different terminal that indexes this genome?")
                print(("if you are sure, remove the directory with 'rm -rf %s' and retry" % dbTmpDir))
                if not FORCE:
                    sys.exit(1)
            else:
                os.makedirs(dbTmpDir)

        if isdir(finalDbDir) and not onlyGenes:
            print("the directory %s already exists" % finalDbDir)
            print("looks like this genome has already been indexed")
            continue

        sizesTmp = join(dbTmpDir, db+".sizes")
        twoBitTmp = join(dbTmpDir, db+".2bit")
        outFnames = []
        if not onlyGenes and not (FORCE and isfile(sizesTmp)):
            printMsg("Genome: " + db)
            printMsg("Downloading")
            faTmp = join(dbTmpDir, db+".fa")
            url = getEnsDownloadUrls(row.server, row.scientificName, row.sourceName, row.nibPath, "fasta")
            # XX tmp hack
            if str(row.taxId)=="511145":
                url = "ftp://ftp.ensemblgenomes.org/pub/current/bacteria/fasta/bacteria_0_collection/escherichia_coli_str_k_12_substr_mg1655/dna/Escherichia_coli_str_k_12_substr_mg1655.ASM584v2.31.dna_sm.toplevel.fa.gz"
            # XX tmp hack ensembl plants nonsense
            if "Hv_IBSC_PGSB_v2" in url:
                url = url.replace("Hv_IBSC_PGSB_v2", "IBSC_v2")

            cmd = "set -euf -o pipefail; wget %s -O - | zcat > %s" % (url, faTmp)
            runCmd(cmd)

            indexFasta(faTmp, db, twoBitTmp, sizesTmp, outFnames)
        else:
            if not isfile(twoBitTmp):
                twoBitTmp = join(finalDbDir, db+".2bit")

            print(twoBitTmp)
            assert(isfile(twoBitTmp))

            # for the case onlyGenes and no .sizes file yet
            if not isfile(sizesTmp):
                origSizes = join(finalDbDir, db+".sizes")
                cmd = "cp %s %s" % (origSizes, sizesTmp)
                runCmd(cmd)

        # get transcript -> gene table and put in gene symbols where we have them
        printMsg("Downloading ensembl transcripts to gene name table")
        ensToGeneTmp = join(dbTmpDir, db+".ensemblToGeneName.txt")
        parts = row.scientificName.lower().split()
        martPrefix = parts[0][0]+parts[1]

        if row.server=="Ensembl":
            martName = "%s_gene_ensembl" % martPrefix
        else:
            martName = "%s_eg_gene" % martPrefix

        martOpt = ""
        if row.server!="Ensembl":
            egType = row.server.replace("Ensembl","").lower()
            martOpt = "--biomartServer=%s.ensembl.org" % egType
            #martOpt += " --schema=%ss_mart" %  (egType, ENSGRELEASE)
            martOpt += " --schema=%s_mart" %  (egType)

        cmd = """retrBiomart %s %s ensembl_transcript_id ensembl_gene_id external_gene_name | gawk 'BEGIN {OFS="\t"; FS="\t"} {if ($3!="") {$2=$3}; print}' | cut -f1,2 > %s""" % (martOpt, martName, ensToGeneTmp)
        runCmd(cmd, mustRun=False, useSys=True)
        # a hack for ensG deviating again from ensg
        if getsize(ensToGeneTmp)==0:
            cmd = cmd.replace('external_gene_name', "external_gene_id")
            runCmd(cmd)
        assert(isfile(ensToGeneTmp) and getsize(ensToGeneTmp)!=0)

        # segment genome into named exons/non-exons
        printMsg("Downloading gene models and converting to segments")
        segTmp = join(dbTmpDir, "%s.segments.bed" % db)
        gtfUrl = getEnsDownloadUrls(row.server, row.scientificName, row.sourceName, row.nibPath, "gtf")
        gpTmp = join(dbTmpDir, "%s.gp" % db)

        # XX tmp hack ensembl plants nonsense
        if "Hv_IBSC_PGSB_v2" in gtfUrl:
            gtfUrl = gtfUrl.replace("Hv_IBSC_PGSB_v2", "IBSC_v2")

        tmpGffName = join(dbTmpDir, "transcripts.gff")
        cmd    = """wget %(gtfUrl)s -O - | zcat > %(tmpGffName)s""" % locals()
        runCmd(cmd, mustRun=False)
        if getsize(tmpGffName)!=0:
            cmd     = """cat %(tmpGffName)s | grep -v 'exon_number "-1"' | grep -v 'AIG90451' | grep -v AGP50801 | gtfToGenePred -allErrors stdin stdout > %(gpTmp)s""" % locals()
            runCmd(cmd)

            # might use this for assembly hub one day
            bgPred = join(dbTmpDir, "%s.bgp" % db)
            cmd = "genePredToBigGenePred %(gpTmp)s stdout | sort -k1,1 -k2,2n > %(bgPred)s" % locals()
            runCmd(cmd)

            bbTmp = join(dbTmpDir, "%s.bb" % db)
            cmd = "bedToBigBed -type=bed12+ -as=/usr/local/bin/bigGenePred.as %(bgPred)s %(sizesTmp)s %(bbTmp)s -tab" % locals()
            runCmd(cmd)

            cmd    = "genePredToBed %(gpTmp)s stdout | bedToExons stdin stdout | lstOp replace stdin %(ensToGeneTmp)s | sort -u | bedSort stdin stdout | bedOverlapMerge /dev/stdin /dev/stdout | bedBetween stdin /dev/stdout -a -s %(sizesTmp)s | bedSort stdin %(segTmp)s" % locals()
            runCmd(cmd)

            cmd = "rm %s" % ensToGeneTmp
            runCmd(cmd)
            outFnames.extend([segTmp, bbTmp, bgPred])

        printMsg("Moving output files into crispr tool directory")
        outFnames.extend([sizesTmp, twoBitTmp])

        #if not onlyGenes:
            #outFnames.append(twoBitTmp)
            #os.makedirs(finalDbDir)

        moveToDest(outFnames, finalDbDir)

        cmd = "rm -rf %s" % dbTmpDir
        runCmd(cmd)

        writeGenomeInfo(row)

def selectManualGenome(taxIds, options):
    assert(len(taxIds)==1) # can only process one url at a time

    descs = options.desc.split("|")
    name, scName, commonName, description = descs
    # description : mis-nomer, description should be called "version"
    url = taxIds[0]
    server = "manual"

    headers = ["name", "description", "genome", "scientificName", "url", "server"]
    Rec = namedtuple("genomeDesc", headers)
    return [Rec(name, description, commonName, scName, url, server)]

def convertGff3(chromSizesFname, gff3Fname, gpFname, segFname, useAltProg):
    " convert gff3 to genePred and segments "
    if gff3Fname.endswith(".gz"):
        catCmd = "zcat"
    else:
        catCmd = "cat"

    if useAltProg:
        # UCSC's program is optimized for NCBI RefSeq GFFs
        # cmd = "gff3ToGenePred %(gff3Fname)s %(gpFname)s -geneNameAttr=gene -rnaNameAttr=transcript_id" % \
        cmd = "gff3ToGenePred %(gff3Fname)s %(gpFname)s -refseqHacks " % \
            locals()
    else:
        cmd = "%(catCmd)s %(gff3Fname)s | gffread /dev/stdin -T -o /dev/stdout | gtfToGenePred -allErrors stdin %(gpFname)s" % locals()

    logging.info("converting gff3 to genePred: %s" % cmd)
    runCmd(cmd, mustRun=False)
    if not isfile(gpFname):
        raise Exception("Problem occured when converting to genePred file")

    if getsize(gpFname)==0:
        logging.info("Genepred file has 0 size. No gene models are available")
        return False

    # genePredTo cannot deal with spaces, so replace these with underscores. 
    # No idea why NCBI has spaces in gene identifiers, in some obscure cases
    cmd = """cat %(gpFname)s | awk 'BEGIN {FS=OFS="\t";} // { gsub(" " , "_", $1); gsub(" ", "_", $12); print }' | genePredToBed stdin stdout | bedToExons stdin stdout | sort -u | bedSort stdin stdout | bedOverlapMerge /dev/stdin /dev/stdout | bedBetween stdin /dev/stdout -a -s %(chromSizesFname)s | bedSort stdin %(segFname)s""" % locals()
    logging.info("converting genePred to segment names: %s" % cmd)
    runCmd(cmd)

    return True

def getFastaAndGff(genomeRows, gff3Fname, options):
    """
    copy local fasta file or wget URL and index it. Also convert gff to genePred
    """
    for row in genomeRows:
        db = row.name
        dbTmpDir = join(tmpDir, db)
        finalDbDir = join(crisprGenomeDir, db)

        if not options.onlyGenes:
            if isdir(dbTmpDir):
                print(("there exists already a directory %s" % dbTmpDir))
                print ("are you sure there is not already a process in a different terminal that indexes this genome?")
                print(("if you are sure, remove the directory with 'rm -rf %s' and retry" % dbTmpDir))
                sys.exit(1)
            else:
                    os.makedirs(dbTmpDir)

            if isdir(finalDbDir):
                print("the directory %s already exists" % finalDbDir)
                print("looks like this genome has already been indexed")
                continue

        printMsg("Genome: " + db)
        printMsg("Downloading")
        faTmp = join(dbTmpDir, db+".fa")

        # download file
        outFnames = []
        if not options.onlyGenes:
            liftFname = copyCheckFa(row.url, faTmp)
            if liftFname:
                outFnames.append(liftFname)
            #if row.url.startswith("http://") or row.url.startswith("ftp://"):
                #if row.url.endswith(".gz"):
                    #cmd = "wget %s -O - | zcat > %s" % (row.url, faTmp)
                #else:
                    #cmd = "wget %s -O %s" % (row.url, faTmp)
                #runCmd(cmd)
            #else:
                # local file, just copy
                #if row.url.endswith(".gz"):
                    #faTmp += ".gz"
                #print("Copy %s to %s" % (row.url, faTmp))
                #shutil.copy(row.url, faTmp)


        twoBitTmp = join(dbTmpDir, db+".2bit")
        sizesTmp = join(dbTmpDir, db+".sizes")
        indexFasta(faTmp, db, twoBitTmp, sizesTmp, outFnames)
        outFnames.extend([sizesTmp, twoBitTmp])


        if gff3Fname:
            #printMsg("Making chrom sizes")
            #cmd = "twoBitInfo %s %s" % (twoBitTmp, sizesTmp)
            #runCmd(cmd)

            gpTmp = join(dbTmpDir, db+".gp")
            segTmp = join(dbTmpDir, "%s.segments.bed" % db)

            useAltGffConv = False
            if options.altGff:
                useAltGffConv = True
            convertGff3(sizesTmp, gff3Fname, gpTmp, segTmp, useAltGffConv)
            outFnames.extend([gpTmp, segTmp])

        moveToDest(outFnames, finalDbDir)

        writeGenomeInfo(row)

def getNcbiIndex(dbType):
    " return path of local copy of refseq assembly index or download "
    fname = join(tmpDir, "assembly_summary_%s.txt" % dbType)
    if isfile(fname):
        logging.info("%s already exists, not downloading again" % fname)
        return fname
    if dbType=="refseq":
        url = "ftp://ftp.ncbi.nlm.nih.gov/genomes/refseq/assembly_summary_refseq.txt"
    else:
        url = "ftp://ftp.ncbi.nlm.nih.gov/genomes/genbank/assembly_summary_genbank.txt"
    cmd = "wget %s -O %s" % (url, fname)
    logging.info("Downloading %s" % url)
    runCmd(cmd)
    return fname

def getNameForTaxId(taxId):
    import xml.etree.ElementTree as etree
    taxId = int(taxId)
    url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=taxonomy&id=%d" % taxId
    data = urlopen(url).read()
    root = etree.fromstring(data)
    nameEls = list(reversed(root.findall("Taxon/OtherNames/CommonName")))
    if len(nameEls)==0:
        nameEls = root.findall("Taxon/OtherNames/GenbankSynonym")
        if len(nameEls)==0:
            nameEls = root.findall("Taxon/OtherNames/GenbankCommonName")
            if len(nameEls)==0:
                nameEls = root.findall("Taxon/OtherNames/Synonym")
                if len(nameEls)==0:
                    return None
    return nameEls[0].text

def getNcbiInfo(fname, acc):
    " get info about assembly via eutils "

    for row in lineFileNext(open(fname), skipLines=1):
        if row.assembly_accession==acc:
            name = acc
            # description : mis-nomer, description should be called "version"
            scName = row.organism_name
            commonName = row.organism_name
            description = "NCBI "+acc+" ("+row.asm_name+")"
            url = acc
            server = "refseq"
            ftpUrl = row.ftp_path
            commonName = getNameForTaxId(row.taxid)
            if commonName is None:
                logging.info("NCBI Taxonomy has no common name for tax ID %s" % row.taxid)
                commonName = scName

            headers = ["name", "description", "genome", "scientificName", "url", "server"]
            Rec = namedtuple("genomeDesc", headers)
            return Rec(name, description, commonName, scName, url, server), ftpUrl

    return None, None

def getGenbankInfo(acc):
    " given a genbank ID, return genome info "
    import xml.etree.ElementTree as etree
    url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&id=%s&rettype=native&retmode=xml" % acc
    data = urlopen(url).read()
    root = etree.fromstring(data)
    orgRefEl = root.findall("Bioseq-set_seq-set/Seq-entry/Seq-entry_set/Bioseq-set/Bioseq-set_descr/Seq-descr/Seqdesc/Seqdesc_source/BioSource/BioSource_org/Org-ref")[0]
    taxName = orgRefEl.findall("Org-ref_taxname")[0].text
    taxId = int(orgRefEl.findall("Org-ref_db/Dbtag/Dbtag_tag/Object-id/Object-id_id")[0].text)
    name = "gb"+acc
    strains = []
    acronyms = []
    for orgModelEl in orgRefEl.findall("Org-ref_orgname/OrgName/OrgName_mod/OrgMod"):
        if orgModelEl.findall("OrgMod_subtype")[0].attrib.get("value")=="strain":
            strains.append(orgModelEl.findall("OrgMod_subname")[0].text)
        if orgModelEl.findall("OrgMod_subtype")[0].attrib.get("value")=="acronym":
            acronyms.append(orgModelEl.findall("OrgMod_subname")[0].text)

    scName = taxName
    if len(strains)!=0:
        scName = scName + ", strain: "+(";".join(strains))

    description = "Genbank "+acc
    url = acc
    server = "genbank"
    commonName = getNameForTaxId(taxId)
    if commonName is None:
        logging.info("NCBI Taxonomy has no common name for tax ID %s" % row.taxid)
        commonName = scName
    if len(acronyms)!=0:
        commonName = commonName + " ("+(", ".join(acronyms))+")"

    headers = ["name", "description", "genome", "scientificName", "url", "server"]
    Rec = namedtuple("genomeDesc", headers)
    return Rec(name, description, commonName, scName, url, server)

def getGenbankGenome(genomeInfo):
    " download genbank sequence and index it "
    logging.info("Adding genome: %s" % repr(genomeInfo))
    db = genomeInfo.name
    dbTmpDir = join(tmpDir, db)
    if isdir(dbTmpDir):
        print(("there exists already a directory %s" % dbTmpDir))
        print ("are you sure there is not already a process in a different terminal that indexes this genome?")
        print(("if you are sure, remove the directory with 'sudo rm -rf %s' and retry" % dbTmpDir))
        sys.exit(1)

    os.makedirs(dbTmpDir)
    finalDbDir = join(crisprGenomeDir, db)
    sizesTmp = join(dbTmpDir, db+".sizes")
    faTmp = join(dbTmpDir, db+".fa")
    twoBitTmp = join(dbTmpDir, db+".2bit")
    gffTmp = None
    outFnames = []

    #if not isfile(sizesTmp):
    printMsg("Downloading genome and uncompressing (for bwa)")
    url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&id=%s&rettype=fasta&retmode=text" % acc
    cmd = "wget '%s' -O  %s" % (url, faTmp)
    runCmd(cmd)
    indexFasta(faTmp, db, twoBitTmp, sizesTmp, outFnames)
    outFnames.extend([sizesTmp, twoBitTmp])

    # no GFF ?

    moveToDest(outFnames, finalDbDir)
    writeGenomeInfo(genomeInfo)


def makeChrUn(fname):
    " create a chrUn and a lift file for it "
    cmd = "faFilter -maxSize=%d %s /tmp/smallSeqs.fa" % (smallCutoff, fname)
    runCmd(cmd)
    cmd = "faFilter -v -maxSize=%d %s /tmp/bigSeqs.fa" % (smallCutoff, fname)
    runCmd(cmd)
    cmd = "faCat /tmp/smallSeqs.fa /tmp/chrUn /tmp/chrUnLft -gapSize=100 -maxOutputSize=99999999999"
    runCmd(cmd)
    cmd = "sed -i s/chrUn\.1/chrUn/ /tmp/chrUn.1.fa"
    runCmd(cmd)
    cmd = "sed -i s/chrUn\.1/chrUn/ /tmp/chrUnLft.1.lft"
    runCmd(cmd)

    newFname = fname+".new"
    cmd = "cat /tmp/bigSeqs.fa /tmp/chrUn.1.fa > %s" % newFname
    runCmd(cmd)
    cmd = "mv %s %s" % (newFname, fname)
    runCmd(cmd)
    cmd = "mv /tmp/chrUnLft.1.lft /tmp/chrUn.lft"
    runCmd(cmd)
    return '/tmp/chrUn.lft'

def copyCheckFa(inUrlOrFname, faFname):
    """ validate fasta file:
    - make sure that seqIds contains only alnum characters, merge contigs into chrUn if needed
    - exit with err code one if not.
    """
    print("Copying fasta file %s to %s" % (inUrlOrFname, faFname))
    if inUrlOrFname.startswith("http") or inUrlOrFname.startswith("ftp"):
        ifh = urlopen(inUrlOrFname)
        if inUrlOrFname.endswith(".gz"):
            #ifh = StringIO.StringIO(gzip.decompress(ifh.read())) # wasteful with RAM, but whatever...
            ifh = gzip.GzipFile(fileobj=StringIO.StringIO(ifh.read()))
    elif inUrlOrFname.endswith(".gz"):
        ifh = gzip.open(inUrlOrFname)
    else:
        ifh = open(inUrlOrFname)

    ofh = open(faFname, "w")

    seqCount = 0
    for line in ifh:
        line = line.rstrip("\n\r")
        if line.startswith(">"):
            seqCount +=1
            seqId = line.lstrip(">")
            seqId = seqId.split()[0]
            if "|" in seqId:
                logging.error("seqId %s in fasta file contains the | character. This is not allowed for crispor." % seqId)
                sys.exit(1)
            if not re.match("[a-zA-Z0-9._-]*", seqId):
                logging.error("seqId %s in fasta file contains unusual characters. Please fix or contact us." % seqId)
                sys.exit(1)
            if len(seqId) > 50:
                logging.error("seqId %s in fasta file is longer than 50 chars. That seems very long." % seqId)
                sys.exit(1)
            ofh.write(">%s\n" % seqId)
        else:
            ofh.write("%s\n" % line)

    ofh.close()

    maxCount = 130000
    if seqCount > maxCount:
        logging.error("This file contains %d, which is more than our limit of %d sequences (contigs?). This means a very poor quality assembly. I will try to work around it by creating an artifical chrUn chromosome with all sequences < %d bp. Gene annotations will not be available for this artificial chromosome." % (seqCount, maxCount, smallCutoff))
        liftFname = makeChrUn(ofh.name)
        return liftFname
    else:
        return None

def getNcbiGenome(ftpUrl, genomeInfo, options):
    " download refseq genome and index it "
    db = genomeInfo.name
    dbTmpDir = join(tmpDir, db)
    if not isdir(dbTmpDir):
        os.makedirs(dbTmpDir)
    finalDbDir = join(crisprGenomeDir, db)
    sizesTmp = join(dbTmpDir, db+".sizes")
    faTmp = join(dbTmpDir, db+".fa")

    ncbiAsmDesc = genomeInfo.description.split("(")[-1].rstrip(")").replace(",", "").replace("+", "_")
    # some names includes commas, see https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/721/785/GCF_000721785.1_Aureobasidium_pullulans_var._pullulans_EXF-150_assembly_version_1.0/
    baseFtp = ftpUrl+"/"+genomeInfo.name+"_"+ncbiAsmDesc+"_genomic"
    baseFtp = baseFtp.replace(" ", "_") # some ncbiAsmDescs include spaces
    faFtpUrl = baseFtp + ".fna.gz"

    outFnames = []

    hasChrUn = False

    if not isfile(sizesTmp) or FORCE:
        printMsg("Downloading genome and uncompressing (for bwa)")
        #cmd = "wget %s -O - | zcat > %s" % (faFtpUrl, faTmp)
        #runCmd(cmd)
        liftFname = copyCheckFa(faFtpUrl, faTmp)
        if liftFname:
            hasChrUn = True
            outFnames.append(liftFname)

    gffTmp = None

    if options.gffFname:
        gffTmp = options.gffFname
    else:
        #if not "GCA_" in faFtpUrl and not hasChrUn:
        gffTmp = join(dbTmpDir, db+".gff")
        gffFtpUrl = baseFtp + ".gff.gz"
        printMsg("Downloading gff")
        cmd = "wget %s -O %s.gz" % (gffFtpUrl, gffTmp)
        ret = runCmd(cmd, mustRun=False)
        if ret!=0:
            gffTmp = None
            logging.warn("Genome has no GFF file. This is pretty common for GCA_ assemblies.")
        else:
            cmd = "gunzip -f %s.gz" % (gffTmp)
            runCmd(cmd)

    twoBitTmp = join(dbTmpDir, db+".2bit")
    indexFasta(faTmp, db, twoBitTmp, sizesTmp, outFnames)
    outFnames.extend([sizesTmp, twoBitTmp])

    #printMsg("Making chrom sizes")
    #cmd = "twoBitInfo %s %s" % (twoBitTmp, sizesTmp)
    #runCmd(cmd)

    gpTmp = join(dbTmpDir, db+".gp")
    segTmp = join(dbTmpDir, "%s.segments.bed" % db)
    useAltProg = True
    if options.gffFname:
        useAltProg = False

    if gffTmp is None:
        hasGff = False
    else:
        hasGff = convertGff3(sizesTmp, gffTmp, gpTmp, segTmp, useAltProg)

    if hasGff:
        outFnames.extend([gpTmp, segTmp])
    else:
        logging.info("Assembly has no gene annotation, skipping genePred step")

    moveToDest(outFnames, finalDbDir)

    writeGenomeInfo(genomeInfo)

# ----------- MAIN --------------
if args==[]:
    parser.print_help()
    exit(1)

if options.debug:
    debugMode = True
if options.force:
    FORCE = True

crisprGenomeDir = options.baseDir

site = args[0]
inIds = args[1:]

if site=="ucsc":
    genomeRows = selectUcscGenomes(inIds, options.auto)
    getUcscGenomes(genomeRows, options.geneTable, options.symFixFile, options.onlyGenes)

elif site=="ucscLocal":
    db = args[1]
    genomeRows = selectUcscGenomesByDb(db)
    indexLocalGenome(genomeRows[0], options.geneTable)

elif site=="ens":
    genomeRows = selectEnsGenomes(inIds)
    getEnsGenomes(genomeRows, options.onlyGenes)

elif site=="fasta":
    genomeRows = selectManualGenome(inIds, options)
    getFastaAndGff(genomeRows, options.gffFname, options)

elif site=="ncbi":
    for acc in inIds:
        fname = getNcbiIndex("refseq")
        genomeInfo, ftpUrl = getNcbiInfo(fname, acc)
        if genomeInfo is None:
            fname = getNcbiIndex("genbank")
            genomeInfo, ftpUrl = getNcbiInfo(fname, acc)
        if genomeInfo is None:
            errAbort("Could not find accession %s, not in RefSeq and neither in Genbank. You want to remove the temp file to trigger a re-download of NCBI organism data." % acc)

        getNcbiGenome(ftpUrl, genomeInfo, options)

elif site=="genbank":
    for acc in inIds:
        genomeInfo = getGenbankInfo(acc)
        getGenbankGenome(genomeInfo)

else:
    raise Exception("site has to be ucsc, ucscLocal, ens, ncbi or genbank")

cmd = "cd /data/www/crispor && ./makeGenomeInfo"
runCmd(cmd)
